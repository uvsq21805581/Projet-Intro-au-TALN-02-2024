{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Séparation test et entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_df.to_csv('../data/train.csv', index=False)\n",
    "# test_df.to_csv('../data/test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ouvrir les csv qui ont déjà été divisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df['recette']\n",
    "y_train = train_df['type']\n",
    "y_test = test_df['type']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_prediction():\n",
    "    return random.choice(['Plat principal', 'Entrée', 'Dessert'])\n",
    "\n",
    "test_df['random prediction'] = test_df.apply(lambda x: random_prediction(), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction classe majoritaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_class_prediction(train_df):\n",
    "    main_type = train_df['type'].mode()    \n",
    "    return main_type\n",
    "\n",
    "main_type = main_class_prediction(train_df)\n",
    "test_df['main class prediction'] = test_df.apply(lambda x: main_type, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger les ressources nécessaires pour nltk (la première fois seulement)\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def normalize_text(text):\n",
    "    # Conversion en minuscules\n",
    "    text = text.lower()\n",
    "    # Suppression de la ponctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Suppression des mots vides\n",
    "    stop_words = set(stopwords.words('french'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatisation\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Rejoindre les tokens en une seule chaîne de caractères\n",
    "    normalized_text = ' '.join(tokens)\n",
    "    return normalized_text\n",
    "\n",
    "# Appliquer la normalisation à une colonne du DataFrame\n",
    "train_df['recette_normalized'] = train_df['recette'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKlearn + Tfi-Df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TfiDf_Sklearn(x_train, y_train, test_df):\n",
    "    \n",
    "    model1 = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "    model1.fit(x_train, y_train)\n",
    "\n",
    "    y_pred_Sklearn = model1.predict(test_df['recette'])\n",
    "\n",
    "    test_df['Tfi-Df prediction'] = y_pred_Sklearn\n",
    "\n",
    "    return y_pred_Sklearn\n",
    "\n",
    "y_pred_Sklearn = TfiDf_Sklearn(x_train, y_train, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_Sklearn_normalized = TfiDf_Sklearn(train_df['recette_normalized'], y_train, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spacyclassifier(x_train, y_train, test_df):\n",
    "    model2 = make_pipeline()\n",
    "\n",
    "    model2.fit(x_train, y_train)\n",
    "\n",
    "    y_pred_spacy = model2.predict(test_df['recette'])\n",
    "\n",
    "    test_df['spacy prediction'] = y_pred_spacy\n",
    "\n",
    "    return y_pred_spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(y_model, y_test):\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_model)\n",
    "\n",
    "    conf_df = pd.DataFrame(conf_matrix)\n",
    "\n",
    "    print(\"Matrice de Confusion : \\n\")\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(conf_df, annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "    plt.title('Matrice de Confusion')\n",
    "    plt.xlabel('Prédictions')\n",
    "    plt.ylabel('Valeurs Réelles')\n",
    "    plt.show()\n",
    "\n",
    "    # Rappel - Precision - F1-score\n",
    "\n",
    "    report = classification_report(y_test, y_model)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rand = test_df['random prediction']\n",
    "results(y_rand, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_main = test_df['main class prediction']\n",
    "results(y_main, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn + Tfi-DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(y_pred_Sklearn, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sklearn + Tfi-Df avec texte normalisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(y_pred_Sklearn_normalized, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"Results for y_pred_Sklearn:\")\n",
    "print(classification_report(y_test, y_pred_Sklearn))\n",
    "\n",
    "print(\"Results for y_pred_Sklearn_normalized:\")\n",
    "print(classification_report(y_test, y_pred_Sklearn_normalized))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
