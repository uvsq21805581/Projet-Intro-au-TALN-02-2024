{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Séparation test et entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# train_df.to_csv('../data/train.csv', index=False)\n",
    "# test_df.to_csv('../data/test.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ouvrir les csv qui ont déjà été divisés"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('../data/train.csv')\n",
    "test_df = pd.read_csv('../data/test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train_df['recette']\n",
    "y_train = train_df['type']\n",
    "y_test = test_df['type']\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction aléatoire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_prediction():\n",
    "    return random.choice(['Plat principal', 'Entrée', 'Dessert'])\n",
    "\n",
    "test_df['random prediction'] = test_df.apply(lambda x: random_prediction(), axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prédiction classe majoritaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_class_prediction(train_df):\n",
    "    main_type = train_df['type'].mode()    \n",
    "    return main_type\n",
    "\n",
    "main_type = main_class_prediction(train_df)\n",
    "test_df['main class prediction'] = test_df.apply(lambda x: main_type, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Télécharger les ressources nécessaires pour nltk (la première fois seulement)\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def normalize_text(text):\n",
    "    # Conversion en minuscules\n",
    "    text = text.lower()\n",
    "    # Suppression de la ponctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    # Suppression des mots vides\n",
    "    stop_words = set(stopwords.words('french'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # Lemmatisation\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    # Rejoindre les tokens en une seule chaîne de caractères\n",
    "    normalized_text = ' '.join(tokens)\n",
    "    return normalized_text\n",
    "\n",
    "# Appliquer la normalisation à une colonne du DataFrame\n",
    "train_df['recette_normalized'] = train_df['recette'].apply(normalize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MultinomialNB_classifier(x_train, y_train, test_df):\n",
    "    \n",
    "    model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(test_df['recette'])\n",
    "\n",
    "    test_df['Tfi-Df prediction'] = y_pred\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "y_pred_MultNB = MultinomialNB_classifier(x_train, y_train, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avec normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_MultNB_normalized = MultinomialNB_classifier(train_df['recette_normalized'], y_train, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest(x_train, y_train, test_df):\n",
    "    model = make_pipeline(TfidfVectorizer(), RandomForestClassifier())\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(test_df['recette'])\n",
    "\n",
    "    test_df['RandomForest Prediction'] = y_pred\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "y_pred_rf = RandomForest(x_train, y_train, test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseau de neuronnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prétraitement des données\n",
    "vectorizer = CountVectorizer()\n",
    "x_train_counts = vectorizer.fit_transform(x_train)\n",
    "x_test_counts = vectorizer.transform(test_df['recette'])\n",
    "\n",
    "# Convertir les étiquettes en format numérique\n",
    "label_to_idx = {'Entrée': 0, 'Plat principal': 1, 'Dessert': 2}\n",
    "y_train_idx = [label_to_idx[label] for label in y_train]\n",
    "\n",
    "# Définition du modèle\n",
    "class RecipeClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(RecipeClassifier, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out\n",
    "\n",
    "input_size = x_train_counts.shape[1]\n",
    "hidden_size = 100\n",
    "num_classes = 3\n",
    "model = RecipeClassifier(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Définition de la fonction de perte et de l'optimiseur\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Entraînement du modèle\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    inputs = torch.tensor(x_train_counts.toarray(), dtype=torch.float32)\n",
    "    labels = torch.tensor(y_train_idx, dtype=torch.long)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, labels)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    print(\"Epoch [\", epoch+1, \"/\", num_epochs, \"]\")\n",
    "\n",
    "# Évaluation du modèle\n",
    "with torch.no_grad():\n",
    "    inputs = torch.tensor(x_test_counts.toarray(), dtype=torch.float32)\n",
    "    outputs = model(inputs)\n",
    "    _, predicted = torch.max(outputs, 1)\n",
    "    predicted_labels = [list(label_to_idx.keys())[list(label_to_idx.values()).index(idx)] for idx in predicted]\n",
    "\n",
    "test_df['Neural Network prediction'] = predicted_labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVC_classifier(x_train, y_train, test_df):\n",
    "\n",
    "    model = make_pipeline(TfidfVectorizer(), SVC())\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    y_pred = model.predict(test_df['recette'])\n",
    "\n",
    "    test_df['SVC prediction'] = y_pred\n",
    "\n",
    "    return y_pred\n",
    "\n",
    "y_pred_SVC = SVC_classifier(x_train, y_train, test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Résultat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def results(y_model, y_test):\n",
    "\n",
    "    conf_matrix = confusion_matrix(y_test, y_model)\n",
    "\n",
    "    conf_df = pd.DataFrame(conf_matrix)\n",
    "\n",
    "    print(\"Matrice de Confusion : \\n\")\n",
    "\n",
    "    plt.figure(figsize=(8,6))\n",
    "    sns.heatmap(conf_df, annot=True, cmap=\"YlGnBu\", fmt='g')\n",
    "    plt.title('Matrice de Confusion')\n",
    "    plt.xlabel('Prédictions')\n",
    "    plt.ylabel('Valeurs Réelles')\n",
    "    plt.show()\n",
    "\n",
    "    # Rappel - Precision - F1-score\n",
    "\n",
    "    report = classification_report(y_test, y_model)\n",
    "    print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_rand = test_df['random prediction']\n",
    "results(y_rand, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_main = test_df['main class prediction']\n",
    "results(y_main, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinobinialeNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(y_pred_MultNB, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MultinomialNB avec texte normalisé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(y_pred_MultNB_normalized, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparaison entre normalisé et non normalisé pour MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Results for y_pred_MultNB:\")\n",
    "print(classification_report(y_test, y_pred_MultNB))\n",
    "\n",
    "print(\"Results for y_pred_MultNB_normalized:\")\n",
    "print(classification_report(y_test, y_pred_MultNB_normalized))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(y_pred_rf, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(y_pred_SVC, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Réseau de neurones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results(predicted_labels, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
